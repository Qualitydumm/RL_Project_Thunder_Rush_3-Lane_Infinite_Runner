# âš¡Thunder Rush: 3-Lane Infinite Runner RL Agentâš¡

Thunder RushëŠ” **3-lane ë¬´í•œ ë‹¬ë¦¬ê¸° ê²Œì„ í™˜ê²½**ì—ì„œ  
Agentê°€ **ë‘ ê°œì˜ ê°•í™”í•™ìŠµ(DQN, PPO) ì•Œê³ ë¦¬ì¦˜** ìœ¼ë¡œ ì¥ì• ë¬¼ì„ íšŒí”¼í•˜ë©° ìµœëŒ€í•œ ì˜¤ë˜ ìƒì¡´í•˜ë„ë¡ í•™ìŠµí•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

í™˜ê²½ ì„¤ê³„ë¶€í„° RL ì•Œê³ ë¦¬ì¦˜(DQN, PPO) ë¹„êµÂ·ê°œì„ ê¹Œì§€ ì§ì ‘ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

---

## ğŸ¯ í”„ë¡œì íŠ¸ ì†Œê°œ (Project Overview)

- **ëª©í‘œ:** Agentê°€ ì¥ì• ë¬¼ì„ íšŒí”¼í•˜ë©° ìµœì¥ ìƒì¡´ ì‹œê°„ ë‹¬ì„±
- **í™˜ê²½:** 3-Lane Infinite Runner (custom Gym-like environment)
- **ì•Œê³ ë¦¬ì¦˜:** Double+â€‹Dueling DQN, PPO+GAE
- **í•™ìŠµ ë°©ì‹:** Vectorized Parallel Training  
  - DQN: 256 environments  
  - PPO: 64 environments
    
---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° (Project Structure)

```text
RL_Project_Thunder_Rush_3-Lane_Infinite_Runner/
â”œâ”€ Codes/                  # ì‹¤í—˜ì— ì‚¬ìš©í•œ ì£¼ìš” Python ì½”ë“œë“¤
â”‚  â”œâ”€ train_dqn_vector_seed_0.py
â”‚  â”œâ”€ train_dqn_vector_seed_1.py
â”‚  â”œâ”€ train_dqn_vector_seed_2.py
â”‚  â”œâ”€ train_ppo_vector_seed_0.py
â”‚  â”œâ”€ train_ppo_vector_seed_1.py
â”‚  â”œâ”€ train_ppo_vector_seed_2.py
â”‚  â”œâ”€ subway_env_latency_test.py   # í™˜ê²½ ë Œë”ë§/latency í…ŒìŠ¤íŠ¸ìš©
â”‚  â””â”€ stats_logger.py              # í•™ìŠµ ë¡œê·¸ í†µê³„ ë¶„ì„
â”œâ”€ Models/                    # í•™ìŠµëœ DQN / PPO ëª¨ë¸ ê°€ì¤‘ì¹˜
â”‚  â”œâ”€ dqn_vector_best_seed*.pth	   # DQN ê° ì‹œë“œë³„ ìµœê³  ëª¨ë¸
â”‚  â””â”€ ppo_vector_best_seed*.pth    # PPO ê° ì‹œë“œë³„ ìµœê³  ëª¨ë¸
â”œâ”€ assets/                    # ê²Œì„ í”Œë ˆì´ GIF, í•™ìŠµ ê³¡ì„  ì´ë¯¸ì§€ ë“±
â”œâ”€ Stats/ 					  # í•™ìŠµ ë¡œê·¸ í†µê³„ csv íŒŒì¼
â”œâ”€ requirements.txt
â””â”€ README.md
```

---
## ğŸ® Environment Overview 

- **í–‰ë™(Action)** : discrete space(5)
   - 0: ìœ ì§€ (stay)
   - 1: ì™¼ìª½ ì´ë™ (left)
   - 2: ì˜¤ë¥¸ìª½ ì´ë™ (right) 
   - 3: ì í”„ (jump)
   - 4: ìŠ¬ë¼ì´ë“œ (slide)
    
- **ì¥ì• ë¬¼ íƒ€ì…(Obstacles)** 
  - **A**: ì í”„ë¡œë§Œ íšŒí”¼ ê°€ëŠ¥
  - **B**: ìŠ¬ë¼ì´ë“œë¡œë§Œ íšŒí”¼ ê°€ëŠ¥
  - **C**: í”¼í•  ìˆ˜ ì—†ëŠ” íŒ¨í„´ (unavoidable) / ì¢Œìš°ì´ë™ìœ¼ë¡œë§Œ íšŒí”¼ ê°€ëŠ¥

- **ìƒíƒœ(State) ì˜ˆì‹œ**
```python
  [player_lane, speed, time_ratio,
   lane0_exists, lane0_dist, lane0_type,
   lane1_exists, lane1_dist, lane1_type,
   lane2_exists, lane2_dist, lane2_type, ...] 
```

- **ë³´ìƒ(Reward)**
  - ê¸°ë³¸ ìƒì¡´ ë³´ìƒ 
    ë§¤ time step ë§ˆë‹¤ +0.1
  - ì¥ì• ë¬¼ íšŒí”¼ ë³´ìƒ
    ì¥ì• ë¬¼ì´ dist â‰¤ 0ì— ë„ë‹¬í•˜ë©´ ì§€ë‚˜ê°„ ê²ƒìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ë³´ìƒì„ ë¶€ì—¬
    - A/B ì¥ì• ë¬¼
      ì ì ˆí•œ action: +2.0
      ë‹¤ë¥¸ actionìœ¼ë¡œ ìƒì¡´: +1.0
    - C ì¥ì• ë¬¼
      ì ì ˆí•œ action: +2.0
      í‹€ë¦° action: episode terminate
  - Penalty
    - ì´ë™ penalty : ë¶ˆí•„ìš”í•œ lane ì´ë™ì‹œ, -0.01
    - ì¶©ëŒ penalty : ì¥ì• ë¬¼ í”¼í•˜ì§€ ëª»í• ì‹œ -10.0, episode terminate
			(ì‚¬ë§ì‚¬ìœ ëŠ” í†µê³„ë¡œ ì €ì¥ë¨ :  (A_no_jump, B_no_slide, C_unavoidable))

--- 

## ğŸ§  RL Algorithms

ì´ í”„ë¡œì íŠ¸ì—ì„œëŠ” ë‘ ê°€ì§€ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ë¹„êµ/ì‹¤í—˜í•©ë‹ˆë‹¤.

### 1) Double DQN + Dueling Architecture (Vectorized)

- Double DQN:  
  - í–‰ë™ ì„ íƒ: policy_net  
  - Qê°’ í‰ê°€: target_net  
  - max ì—°ì‚°ìœ¼ë¡œ ì¸í•œ Q overestimation ì™„í™”

- Dueling DQN:  
  - Q(s,a) = V(s) + A(s,a) - mean(A(s,Â·))  
  - ìƒíƒœ ê°€ì¹˜ì™€ í–‰ë™ ì´ì ì„ ë¶„ë¦¬í•´ì„œ ë” ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµ
- Vectorized Env:  
  - 256ê°œ í™˜ê²½ ë™ì‹œ ì‹¤í–‰ë¡œ ë§¤ stepë§ˆë‹¤ 256 transition ìˆ˜ì§‘

### 2) PPO + GAE (Proximal Policy Optimization)

- on-policy actorâ€“critic ì•Œê³ ë¦¬ì¦˜
- GAE(Î»)ë¥¼ ì‚¬ìš©í•´ biasâ€“variance trade-off ì¡°ì ˆ
- Clipped objectiveë¡œ ì •ì±… ì—…ë°ì´íŠ¸ í­ì„ ì œí•œí•´ ì•ˆì •ì  í•™ìŠµ
- 64ê°œ í™˜ê²½ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ì—¬ rollout ê¸°ë°˜ í•™ìŠµ

---
## âš™ï¸ ìµœì¢… ì‹¤í—˜ ì„¤ì • (Final Config)

ì•„ë˜ ì„¤ì •ì€ ë³´ê³ ì„œ/ìŠ¬ë¼ì´ë“œì— ì œì‹œëœ ìµœì¢… ê²°ê³¼(DQN_new vs PPO, seed 0Â·1Â·2 í‰ê·  ë° ë¶„ì‚°)ë¥¼ ì–»ì„ ë•Œ ì‚¬ìš©í•œ êµ¬ì„±ì…ë‹ˆë‹¤.  

### ê³µí†µ ì„¤ì •

- í™˜ê²½: `SubwayEnv` (`subway_env_latency_test.py`)
- ê´€ì¸¡ ì°¨ì›: 33
- í–‰ë™ ê³µê°„: 5 (`stay`, `left`, `right`, `jump`, `slide`)
- ì‚¬ìš© seed: `{0, 1, 2}`  (DQN, PPO ëª¨ë‘ ë™ì¼í•œ seed ì§‘í•© ì‚¬ìš©)

### DQN (Dueling Double DQN)

| í•­ëª©                  | ê°’            |
| --------------------- | ------------- |
| num_episodes          | 4,000         |
| num_envs              | 256           |
| buffer_capacity       | 2,000,000     |
| batch_size            | 4,096         |
| gamma                 | 0.99          |
| lr                    | 1e-4          |
| start_learning        | 20,000 steps  |
| learn_every           | 2 steps       |
| target_update_interval| 5,000 steps   |
| epsilon_start         | 1.0           |
| epsilon_end           | 0.01          |
| epsilon_decay_steps   | 500,000 steps |
 
### PPO (PPO + GAE)

| í•­ëª©            | ê°’           |
| --------------- | ------------ |
| num_episodes    | 100,000      |
| num_envs        | 64           |
| rollout_steps   | 256          |
| update_epochs   | 6            |
| mini_batch_size | 1,024        |
| gamma           | 0.99         |
| lam (GAE Î»)     | 0.95         |
| clip_coef       | 0.2          |
| target_kl       | 0.02         |
| lr              | 2.5e-4       |
| entropy_coef    | 0.01         |
| value_coef      | 0.5          |
| max_grad_norm   | 0.5          |

> ìœ„ í‘œì˜ ì„¤ì •ì€ `train_dqn_vector_seed_*.py`, `train_ppo_vector_seed_*.py`ì— ì •ì˜ëœ ìµœì¢… `config/base_config`ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.

## ğŸ¥ ì‹œê° ìë£Œ 

> ê²Œì„ í”Œë ˆì´ ì´ë¯¸ì§€, í•™ìŠµ ê³¡ì„ , ì‚¬ë§ ë¶„í¬ ë“± ë„£ì„ ì˜ˆì •

| ê²Œì„ í™”ë©´ | í•™ìŠµ ë³´ìƒ ê³¡ì„  |
|----------|----------------|
| ![game](assets/gameplay.gif) | ![reward](assets/reward_curve.png) |

(íŒŒì¼ ì¶”ê°€ í›„ ê²½ë¡œ ë§ì¶° ë„£ìœ¼ë©´ ë¨)

---

## ğŸ›  ì„¤ì¹˜ ë°©ë²• (Installation)

```bash
git clone https://github.com/Qualitydumm/RL_Project_Thunder_Rush_3-Lane_Infinite_Runner.git
cd RL_Project_Thunder_Rush_3-Lane_Infinite_Runner

# (ì„ íƒ) ê°€ìƒí™˜ê²½ ê¶Œì¥
# python -m venv venv
# source venv/bin/activate  # Windows: venv\Scripts\activate

pip install -r requirements.txt
```
---

## ğŸ›  ì‚¬ìš©ë²• (Usage)

1) DQN í•™ìŠµ
```
python train_dqn_vector_seed_2.py
```
2) PPO í•™ìŠµ
```
python train_ppo_vector_seed_2.py
```

random seedë§Œ ë‹¤ë¥¸ ë™ì¼ ì‹¤í—˜ ì½”ë“œì´ë©°, ì¬í˜„ì„± ë° ì‹ ë¢°êµ¬ê°„ ë¶„ì„ì„ ìœ„í•´ ì—¬ëŸ¬ ë²„ì „ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.
ì–´ë–¤ seed ë²„ì „ì„ ì‹¤í–‰í•´ë„ ê¸°ë³¸ ë™ì‘ì€ ë™ì¼í•©ë‹ˆë‹¤

## ğŸ”§ ê°œë°œìš© ìœ í‹¸ë¦¬í‹° (Developer Utilities)

í”„ë¡œì íŠ¸ ê°œë°œ ë° ë””ë²„ê¹…ì— ì‚¬ìš©í•œ ë‚´ë¶€ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

```bash
# í™˜ê²½ ë Œë”ë§ / latency í…ŒìŠ¤íŠ¸ìš©
python subway_env_latency_test.py

# í•™ìŠµ ë¡œê·¸ í†µê³„ ë¶„ì„ ë° CSV ì €ì¥
python stats_logger.py
```

## ğŸ“„ License
This project is licensed under the MIT License.
